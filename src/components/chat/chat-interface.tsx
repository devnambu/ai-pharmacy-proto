"use client";

import { useChat } from "@ai-sdk/react";
import { DefaultChatTransport } from "ai";
import { useRef, useEffect, useState, useCallback } from "react";
import { Button } from "@/components/ui/button";
import { ScrollArea } from "@/components/ui/scroll-area";
import { Mic, MicOff, User, Bot, Loader2 } from "lucide-react";
import { cn } from "@/lib/utils";

// ç„¡éŸ³æ¤œå‡ºã®è¨­å®š
const SILENCE_THRESHOLD = 10;   // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã®é–¾å€¤ï¼ˆ0-255ï¼‰
const SILENCE_DURATION = 1000;  // ç„¡éŸ³ã¨åˆ¤å®šã™ã‚‹ã¾ã§ã®æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
const VOICE_THRESHOLD = 12;     // ç™ºè©±é–‹å§‹ã¨åˆ¤å®šã™ã‚‹é–¾å€¤

export function ChatInterface() {
    const { messages, sendMessage, status } = useChat({
        transport: new DefaultChatTransport({
            api: "/api/chat",
        }),
    });

    const [input, setInput] = useState("");
    const scrollRef = useRef<HTMLDivElement>(null);
    const textareaRef = useRef<HTMLTextAreaElement>(null);

    // ãƒã‚¤ã‚¯ã®çŠ¶æ…‹
    const [isMicActive, setIsMicActive] = useState(false);     // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ è‡ªä½“ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹
    const [isListening, setIsListening] = useState(false);      // VADãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ç™ºè©±æ¤œå‡ºä¸­ã‹
    const [isCapturing, setIsCapturing] = useState(false);      // ç¾åœ¨ç™ºè©±ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­ã‹
    const [isTranscribing, setIsTranscribing] = useState(false);
    const [hasStartedOnce, setHasStartedOnce] = useState(false);

    // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆå¸¸æ™‚ONï¼‰
    const streamRef = useRef<MediaStream | null>(null);
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);

    // éŒ²éŸ³ç”¨ï¼ˆç™ºè©±åŒºé–“ã®ã¿ï¼‰
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const audioChunksRef = useRef<Blob[]>([]);

    // VADåˆ¶å¾¡
    const animationFrameRef = useRef<number | null>(null);
    const silenceStartRef = useRef<number | null>(null);
    const hasVoiceDetectedRef = useRef<boolean>(false);
    const isProcessingRef = useRef<boolean>(false);  // æ–‡å­—èµ·ã“ã—â†’é€ä¿¡ä¸­ãƒ•ãƒ©ã‚°

    // Auto-scroll to bottom when new messages arrive
    useEffect(() => {
        if (scrollRef.current) {
            scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
        }
    }, [messages]);

    // ==== ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ç®¡ç† ====

    // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—ï¼ˆ1å›ã®ã¿ï¼‰
    const acquireMicStream = useCallback(async () => {
        if (streamRef.current) return streamRef.current;

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        streamRef.current = stream;

        // AudioContextã¨Analyserã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        const audioContext = new AudioContext();
        audioContextRef.current = audioContext;
        const source = audioContext.createMediaStreamSource(stream);
        const analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        source.connect(analyser);
        analyserRef.current = analyser;

        return stream;
    }, []);

    // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è§£æ”¾
    const releaseMicStream = useCallback(() => {
        // VADã‚’åœæ­¢
        if (animationFrameRef.current) {
            cancelAnimationFrame(animationFrameRef.current);
            animationFrameRef.current = null;
        }
        // éŒ²éŸ³ä¸­ãªã‚‰åœæ­¢
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
            mediaRecorderRef.current.stop();
        }
        mediaRecorderRef.current = null;
        // AudioContextã‚’é–‰ã˜ã‚‹
        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }
        analyserRef.current = null;
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        if (streamRef.current) {
            streamRef.current.getTracks().forEach((track) => track.stop());
            streamRef.current = null;
        }
        // stateãƒªã‚»ãƒƒãƒˆ
        silenceStartRef.current = null;
        hasVoiceDetectedRef.current = false;
        isProcessingRef.current = false;
        setIsMicActive(false);
        setIsListening(false);
        setIsCapturing(false);
    }, []);

    // ==== ç™ºè©±åŒºé–“ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ ====

    // ç™ºè©±åŒºé–“ã®éŒ²éŸ³ã‚’é–‹å§‹
    const startCapture = useCallback(() => {
        if (!streamRef.current || isProcessingRef.current) return;

        const mediaRecorder = new MediaRecorder(streamRef.current, {
            mimeType: "audio/webm;codecs=opus",
        });
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunksRef.current.push(event.data);
            }
        };

        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm" });
            // æœ€å°ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if (audioBlob.size > 1000) {
                await transcribeAndSend(audioBlob);
            } else {
                // å°ã•ã™ãã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ç„¡è¦–ã—ã¦å†é–‹
                isProcessingRef.current = false;
            }
        };

        mediaRecorderRef.current = mediaRecorder;
        mediaRecorder.start(100);
        setIsCapturing(true);
    }, []);

    // ç™ºè©±åŒºé–“ã®éŒ²éŸ³ã‚’åœæ­¢
    const stopCapture = useCallback(() => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
            isProcessingRef.current = true;
            mediaRecorderRef.current.stop();
        }
        mediaRecorderRef.current = null;
        setIsCapturing(false);
        // VADãƒ•ãƒ©ã‚°ãƒªã‚»ãƒƒãƒˆï¼ˆæ¬¡ã®ç™ºè©±åŒºé–“ã®ãŸã‚ã«ï¼‰
        hasVoiceDetectedRef.current = false;
        silenceStartRef.current = null;
    }, []);

    // ==== æ–‡å­—èµ·ã“ã—ãƒ»é€ä¿¡ ====

    const transcribeAndSend = useCallback(async (audioBlob: Blob) => {
        setIsTranscribing(true);

        try {
            const arrayBuffer = await audioBlob.arrayBuffer();
            const base64Audio = btoa(
                new Uint8Array(arrayBuffer).reduce(
                    (data, byte) => data + String.fromCharCode(byte),
                    ""
                )
            );

            const response = await fetch("/api/transcribe", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({
                    audioData: base64Audio,
                    encoding: "WEBM_OPUS",
                    sampleRateHertz: 48000,
                }),
            });

            const result = await response.json();

            if (result.success && result.transcription) {
                const transcribedText = result.transcription.trim();
                if (transcribedText) {
                    setInput(transcribedText);
                    sendMessage({ text: transcribedText });
                    setInput("");
                }
            } else if (!result.success) {
                console.error("æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼:", result.error, result.details);
            }
        } catch (error) {
            console.error("æ–‡å­—èµ·ã“ã—ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:", error);
        } finally {
            setIsTranscribing(false);
            isProcessingRef.current = false;
        }
    }, [sendMessage]);

    // ==== VADï¼ˆVoice Activity Detectionï¼‰ ====

    const startVAD = useCallback(() => {
        if (!analyserRef.current) return;

        const analyser = analyserRef.current;
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        setIsListening(true);

        const checkLevel = () => {
            if (!analyserRef.current) return;
            // å‡¦ç†ä¸­ã¯VADã‚’ä¸€æ™‚åœæ­¢
            if (isProcessingRef.current) {
                animationFrameRef.current = requestAnimationFrame(checkLevel);
                return;
            }

            analyser.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;

            if (average >= VOICE_THRESHOLD) {
                // éŸ³å£°æ¤œå‡º
                if (!hasVoiceDetectedRef.current) {
                    // ç™ºè©±é–‹å§‹ â†’ ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
                    hasVoiceDetectedRef.current = true;
                    startCapture();
                }
                // ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
                silenceStartRef.current = null;
            } else if (average < SILENCE_THRESHOLD && hasVoiceDetectedRef.current) {
                // ç™ºè©±å¾Œã®ç„¡éŸ³
                if (silenceStartRef.current === null) {
                    silenceStartRef.current = Date.now();
                } else if (Date.now() - silenceStartRef.current >= SILENCE_DURATION) {
                    // ç„¡éŸ³ãŒç¶šã„ãŸ â†’ ã‚­ãƒ£ãƒ—ãƒãƒ£åœæ­¢ãƒ»é€ä¿¡
                    console.log("ç„¡éŸ³æ¤œå‡º: ç™ºè©±åŒºé–“ã‚’é€ä¿¡ã—ã¾ã™");
                    stopCapture();
                    animationFrameRef.current = requestAnimationFrame(checkLevel);
                    return;
                }
            }

            animationFrameRef.current = requestAnimationFrame(checkLevel);
        };

        checkLevel();
    }, [startCapture, stopCapture]);

    const stopVAD = useCallback(() => {
        if (animationFrameRef.current) {
            cancelAnimationFrame(animationFrameRef.current);
            animationFrameRef.current = null;
        }
        setIsListening(false);
    }, []);

    // ==== ãƒã‚¤ã‚¯ã®ON/OFF ====

    const activateMic = useCallback(async () => {
        try {
            await acquireMicStream();
            setIsMicActive(true);
            setHasStartedOnce(true);
            startVAD();
        } catch (error) {
            console.error("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
            alert("ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
        }
    }, [acquireMicStream, startVAD]);

    const deactivateMic = useCallback(() => {
        stopVAD();
        releaseMicStream();
    }, [stopVAD, releaseMicStream]);

    const handleMicClick = useCallback(() => {
        if (isMicActive) {
            deactivateMic();
        } else {
            activateMic();
        }
    }, [isMicActive, activateMic, deactivateMic]);

    // ==== AIå¿œç­”å®Œäº†å¾Œã«VADã‚’å†é–‹ ====

    useEffect(() => {
        if (!hasStartedOnce) return;
        if (!isMicActive) return;
        if (isTranscribing) return;

        // AIå¿œç­”ãŒå®Œäº†ã—ãŸã‚‰VADã‚’å†é–‹ï¼ˆãƒã‚¤ã‚¯ã¯ãã®ã¾ã¾ï¼‰
        if (status === "ready" && !isListening && !isProcessingRef.current) {
            const timer = setTimeout(() => {
                startVAD();
            }, 300);
            return () => clearTimeout(timer);
        }
    }, [status, hasStartedOnce, isMicActive, isTranscribing, isListening, startVAD]);

    // AIå¿œç­”é–‹å§‹æ™‚ã«VADã‚’ä¸€æ™‚åœæ­¢
    useEffect(() => {
        if (status === "streaming" || status === "submitted") {
            stopVAD();
            // ã‚­ãƒ£ãƒ—ãƒãƒ£ä¸­ãªã‚‰åœæ­¢ï¼ˆé€ä¿¡ã—ãªã„ï¼‰
            if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
                mediaRecorderRef.current.stop();
                mediaRecorderRef.current = null;
                setIsCapturing(false);
                hasVoiceDetectedRef.current = false;
                silenceStartRef.current = null;
            }
        }
    }, [status, stopVAD]);

    // ==== ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚­ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ ====

    useEffect(() => {
        const handleGlobalKeyDown = (e: KeyboardEvent) => {
            if (document.activeElement === textareaRef.current) return;
            const ae = document.activeElement;
            if (ae && (ae.tagName === "INPUT" || ae.tagName === "TEXTAREA" || (ae as HTMLElement).isContentEditable)) return;

            if (e.key === " " && !e.shiftKey && !isTranscribing) {
                e.preventDefault();
                handleMicClick();
            }
        };

        window.addEventListener("keydown", handleGlobalKeyDown);
        return () => window.removeEventListener("keydown", handleGlobalKeyDown);
    }, [handleMicClick, isTranscribing]);

    // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    useEffect(() => {
        return () => {
            releaseMicStream();
        };
    }, [releaseMicStream]);

    const isLoading = status === "streaming" || status === "submitted";

    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    const getStatusMessage = () => {
        if (!isMicActive) return "ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ä¼šè©±ã‚’é–‹å§‹ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã§ã‚‚å¯ï¼‰";
        if (isTranscribing) return "éŸ³å£°ã‚’èªè­˜ä¸­...";
        if (isLoading) return "æ‚£è€…ãŒå¿œç­”ä¸­...";
        if (isCapturing) return "ğŸ”´ ç™ºè©±ä¸­...";
        if (isListening) return "ğŸ§ è´ã„ã¦ã„ã¾ã™ â€” è©±ã—ã‹ã‘ã¦ãã ã•ã„";
        return "å¾…æ©Ÿä¸­...";
    };

    return (
        <div className="flex flex-col h-screen bg-gradient-to-br from-slate-900 via-slate-800 to-slate-900">
            {/* Header */}
            <header className="flex-shrink-0 border-b border-slate-700/50 bg-slate-800/50 backdrop-blur-sm">
                <div className="max-w-4xl mx-auto px-4 py-4">
                    <div className="flex items-center gap-3">
                        <div className="w-10 h-10 rounded-full bg-gradient-to-br from-emerald-400 to-cyan-500 flex items-center justify-center">
                            <Bot className="w-5 h-5 text-white" />
                        </div>
                        <div>
                            <h1 className="text-lg font-semibold text-white">
                                æœè–¬æŒ‡å°ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤
                            </h1>
                            <p className="text-sm text-slate-400">
                                æ‚£è€…: ä½è—¤ å¥å¤ªï¼ˆ35æ­³ãƒ»ç”·æ€§ãƒ»é«˜è¡€åœ§ï¼‰
                            </p>
                        </div>
                    </div>
                </div>
            </header>

            {/* Chat Messages */}
            <ScrollArea className="flex-1 px-4" ref={scrollRef}>
                <div className="max-w-4xl mx-auto py-6 space-y-4">
                    {messages.length === 0 && (
                        <div className="text-center py-12">
                            <div className="w-16 h-16 mx-auto mb-4 rounded-full bg-gradient-to-br from-emerald-400/20 to-cyan-500/20 flex items-center justify-center">
                                <Bot className="w-8 h-8 text-emerald-400" />
                            </div>
                            <h2 className="text-xl font-semibold text-white mb-2">
                                æœè–¬æŒ‡å°ã‚’å§‹ã‚ã¾ã—ã‚‡ã†
                            </h2>
                            <p className="text-slate-400 max-w-md mx-auto">
                                ã‚ãªãŸã¯è–¬å‰¤å¸«å½¹ã§ã™ã€‚æ‚£è€…ã®ä½è—¤å¥å¤ªã•ã‚“ã«æœè–¬æŒ‡å°ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
                                <br />
                                ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚
                            </p>
                        </div>
                    )}

                    {messages.map((message) => (
                        <div
                            key={message.id}
                            className={cn(
                                "flex gap-3",
                                message.role === "user" ? "justify-end" : "justify-start"
                            )}
                        >
                            {message.role === "assistant" && (
                                <div className="flex-shrink-0 w-8 h-8 rounded-full bg-gradient-to-br from-emerald-400 to-cyan-500 flex items-center justify-center">
                                    <Bot className="w-4 h-4 text-white" />
                                </div>
                            )}

                            <div
                                className={cn(
                                    "max-w-[75%] rounded-2xl px-4 py-3 shadow-lg",
                                    message.role === "user"
                                        ? "bg-gradient-to-r from-blue-500 to-blue-600 text-white"
                                        : "bg-slate-700/80 text-slate-100 backdrop-blur-sm"
                                )}
                            >
                                <div className="text-sm leading-relaxed whitespace-pre-wrap">
                                    {message.parts.map((part, index) =>
                                        part.type === "text" ? (
                                            <span key={index}>{part.text}</span>
                                        ) : null
                                    )}
                                </div>
                            </div>

                            {message.role === "user" && (
                                <div className="flex-shrink-0 w-8 h-8 rounded-full bg-gradient-to-br from-blue-400 to-blue-500 flex items-center justify-center">
                                    <User className="w-4 h-4 text-white" />
                                </div>
                            )}
                        </div>
                    ))}

                    {isLoading && (
                        <div className="flex gap-3 justify-start">
                            <div className="flex-shrink-0 w-8 h-8 rounded-full bg-gradient-to-br from-emerald-400 to-cyan-500 flex items-center justify-center">
                                <Bot className="w-4 h-4 text-white" />
                            </div>
                            <div className="bg-slate-700/80 rounded-2xl px-4 py-3 backdrop-blur-sm">
                                <div className="flex gap-1">
                                    <span className="w-2 h-2 bg-slate-400 rounded-full animate-bounce [animation-delay:-0.3s]"></span>
                                    <span className="w-2 h-2 bg-slate-400 rounded-full animate-bounce [animation-delay:-0.15s]"></span>
                                    <span className="w-2 h-2 bg-slate-400 rounded-full animate-bounce"></span>
                                </div>
                            </div>
                        </div>
                    )}
                </div>
            </ScrollArea>

            {/* Input Area */}
            <div className="flex-shrink-0 border-t border-slate-700/50 bg-slate-800/50 backdrop-blur-sm">
                <div className="max-w-4xl mx-auto px-4 py-4">
                    {/* ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ï¼ˆéè¡¨ç¤ºã ãŒæ®‹ã™ï¼‰ */}
                    <div className="hidden">
                        <textarea
                            ref={textareaRef}
                            value={input}
                            onChange={(e) => setInput(e.target.value)}
                            placeholder="æœè–¬æŒ‡å°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."
                            rows={1}
                            className="w-full resize-none rounded-xl border border-slate-600 bg-slate-700/50 px-4 py-3 pr-10 text-white placeholder-slate-400"
                            disabled={status !== "ready"}
                        />
                    </div>

                    <div className="flex gap-3 items-center justify-center">
                        {/* ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ */}
                        <Button
                            type="button"
                            variant="outline"
                            size="icon"
                            className={cn(
                                "h-20 w-20 rounded-full border-2 transition-all",
                                isCapturing
                                    ? "bg-red-500 border-red-500 text-white hover:bg-red-600 hover:border-red-600 animate-pulse scale-110"
                                    : isTranscribing
                                        ? "bg-amber-500 border-amber-500 text-white"
                                        : isListening
                                            ? "bg-emerald-500 border-emerald-400 text-white animate-pulse"
                                            : isLoading
                                                ? "bg-slate-600 border-slate-600 text-slate-400"
                                                : isMicActive
                                                    ? "bg-emerald-600 border-emerald-500 text-white"
                                                    : "bg-gradient-to-r from-emerald-500 to-cyan-500 border-emerald-500 text-white hover:from-emerald-600 hover:to-cyan-600 hover:scale-105"
                            )}
                            onClick={handleMicClick}
                            disabled={isTranscribing}
                        >
                            {isTranscribing ? (
                                <Loader2 className="h-8 w-8 animate-spin" />
                            ) : isMicActive ? (
                                <MicOff className="h-8 w-8" />
                            ) : (
                                <Mic className="h-8 w-8" />
                            )}
                        </Button>
                    </div>

                    <p className="text-xs text-slate-500 mt-3 text-center">
                        {getStatusMessage()}
                    </p>
                </div>
            </div>
        </div>
    );
}
